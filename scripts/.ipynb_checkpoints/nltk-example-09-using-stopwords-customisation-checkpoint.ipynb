{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re \n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews = [[\"POSITIVE\",\"The product is really good\", [],[], []],\n",
    "           [\"POSITIVE\",\"The products is good\", [],[], []],\n",
    "           [\"POSITIVE\",\"Good product I really liked it\", [],[],[]],\n",
    "           [\"NEGATIVE\",\"I didn't like the product\", [],[], []],\n",
    "           [\"NEGATIVE\",\"The product is not good\", [],[], []]]\n",
    "\n",
    "df = pd.DataFrame(reviews, columns=['label','original_review', 'tokens_raw', \n",
    "                                    \"tokens_default_stopwords\",\"tokens_modified_stopwords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace_tokenizer = RegexpTokenizer(\"\\s+\", gaps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_default = set(stopwords.words('english'))\n",
    "\n",
    "stopwords_modified = set(stopwords.words('english'))\n",
    "stopwords_modified.remove('not')\n",
    "stopwords_modified.remove(\"didn't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    original_review = row['original_review'].lower()\n",
    "    row['tokens_raw'] = whitespace_tokenizer.tokenize(original_review)\n",
    "\n",
    "    for t in row['tokens_raw']:\n",
    "        if not(t in stopwords_default):\n",
    "            row['tokens_default_stopwords'].append(t)\n",
    "        if not(t in stopwords_modified):\n",
    "            row['tokens_modified_stopwords'].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
