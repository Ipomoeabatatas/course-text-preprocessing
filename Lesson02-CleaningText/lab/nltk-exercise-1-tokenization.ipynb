{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing Exercise - Tokenisation\n",
    "\n",
    "#### Introduction\n",
    "Lets download a set of data containing news clipping written in English,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_nr</th>\n",
       "      <th>news_snippets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP880224-0195</td>\n",
       "      <td>The Bechtel Group Inc. offered in 1985 to sell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP881017-0144</td>\n",
       "      <td>A gunman took a 74-year-old woman hostage afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP881017-0219</td>\n",
       "      <td>Today is Saturday, Oct. 29, the 303rd day of 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP900117-0022</td>\n",
       "      <td>Cupid has a new message for lovers this Valent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP880405-0167</td>\n",
       "      <td>The Reagan administration is weighing whether ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AP880825-0239</td>\n",
       "      <td>More than 120,000 skins of a protected species...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AP880325-0232</td>\n",
       "      <td>There will be no organized union boost behind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AP880908-0056</td>\n",
       "      <td>Here is a summary of developments in forest an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AP881105-0097</td>\n",
       "      <td>Jean-Pierre Stirbois, the No. 2 man in the ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AP880716-0112</td>\n",
       "      <td>At least 15 people died and 25,000 residents o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AP880608-0142</td>\n",
       "      <td>Actress Betty Buckley sang ``They Can't Take T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AP881110-0228</td>\n",
       "      <td>For three years, Charles S. Robb was out of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AP900802-0166</td>\n",
       "      <td>An article in the August issue of the glossy W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AP881214-0257</td>\n",
       "      <td>The operating rate at U.S. factories, mines an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AP880401-0081</td>\n",
       "      <td>Ferrets are increasingly popular as pets, but ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_nr                                      news_snippets\n",
       "0   AP880224-0195  The Bechtel Group Inc. offered in 1985 to sell...\n",
       "1   AP881017-0144  A gunman took a 74-year-old woman hostage afte...\n",
       "2   AP881017-0219  Today is Saturday, Oct. 29, the 303rd day of 1...\n",
       "3   AP900117-0022  Cupid has a new message for lovers this Valent...\n",
       "4   AP880405-0167  The Reagan administration is weighing whether ...\n",
       "5   AP880825-0239  More than 120,000 skins of a protected species...\n",
       "6   AP880325-0232  There will be no organized union boost behind ...\n",
       "7   AP880908-0056  Here is a summary of developments in forest an...\n",
       "8   AP881105-0097  Jean-Pierre Stirbois, the No. 2 man in the ext...\n",
       "9   AP880716-0112  At least 15 people died and 25,000 residents o...\n",
       "10  AP880608-0142  Actress Betty Buckley sang ``They Can't Take T...\n",
       "11  AP881110-0228  For three years, Charles S. Robb was out of th...\n",
       "12  AP900802-0166  An article in the August issue of the glossy W...\n",
       "13  AP881214-0257  The operating rate at U.S. factories, mines an...\n",
       "14  AP880401-0081  Ferrets are increasingly popular as pets, but ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_corpus = pd.read_csv('./data/news_clipping.csv',encoding='utf-8')\n",
    "news_corpus.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "\n",
    "1. Tokenize each new clipping into sentences\n",
    "2. The list of sentences should be saved into a new column sentence_tokens within the same dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "1. For each sentences, further tokenize into uni-grams or words.\n",
    "2. The list of sentences should be saved into a new column sentence_word_tokens within the same dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "1. For each sentences, further tokenize into bigrams.\n",
    "2. The list of sentences should be saved into a new column sentence_bigram_tokens within the same dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "1. As you examine the results of the tokenization, you may come across strange combination of symbols, or characters that do not make senses or complicated the tokenization effort. In this case, you may wish to do use regular expression to substitute out these symbols, characters for something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
