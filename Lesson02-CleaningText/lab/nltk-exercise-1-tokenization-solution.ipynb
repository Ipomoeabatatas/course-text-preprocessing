{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing Exercise in Tokenisation\n",
    "\n",
    "#### Introduction\n",
    "Lets download a set of data containing news clipping written in English,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_nr</th>\n",
       "      <th>news_snippets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP880224-0195</td>\n",
       "      <td>The Bechtel Group Inc. offered in 1985 to sell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP881017-0144</td>\n",
       "      <td>A gunman took a 74-year-old woman hostage afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP881017-0219</td>\n",
       "      <td>Today is Saturday, Oct. 29, the 303rd day of 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP900117-0022</td>\n",
       "      <td>Cupid has a new message for lovers this Valent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP880405-0167</td>\n",
       "      <td>The Reagan administration is weighing whether ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AP880825-0239</td>\n",
       "      <td>More than 120,000 skins of a protected species...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AP880325-0232</td>\n",
       "      <td>There will be no organized union boost behind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AP880908-0056</td>\n",
       "      <td>Here is a summary of developments in forest an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AP881105-0097</td>\n",
       "      <td>Jean-Pierre Stirbois, the No. 2 man in the ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AP880716-0112</td>\n",
       "      <td>At least 15 people died and 25,000 residents o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AP880608-0142</td>\n",
       "      <td>Actress Betty Buckley sang ``They Can't Take T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AP881110-0228</td>\n",
       "      <td>For three years, Charles S. Robb was out of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AP900802-0166</td>\n",
       "      <td>An article in the August issue of the glossy W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AP881214-0257</td>\n",
       "      <td>The operating rate at U.S. factories, mines an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AP880401-0081</td>\n",
       "      <td>Ferrets are increasingly popular as pets, but ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_nr                                      news_snippets\n",
       "0   AP880224-0195  The Bechtel Group Inc. offered in 1985 to sell...\n",
       "1   AP881017-0144  A gunman took a 74-year-old woman hostage afte...\n",
       "2   AP881017-0219  Today is Saturday, Oct. 29, the 303rd day of 1...\n",
       "3   AP900117-0022  Cupid has a new message for lovers this Valent...\n",
       "4   AP880405-0167  The Reagan administration is weighing whether ...\n",
       "5   AP880825-0239  More than 120,000 skins of a protected species...\n",
       "6   AP880325-0232  There will be no organized union boost behind ...\n",
       "7   AP880908-0056  Here is a summary of developments in forest an...\n",
       "8   AP881105-0097  Jean-Pierre Stirbois, the No. 2 man in the ext...\n",
       "9   AP880716-0112  At least 15 people died and 25,000 residents o...\n",
       "10  AP880608-0142  Actress Betty Buckley sang ``They Can't Take T...\n",
       "11  AP881110-0228  For three years, Charles S. Robb was out of th...\n",
       "12  AP900802-0166  An article in the August issue of the glossy W...\n",
       "13  AP881214-0257  The operating rate at U.S. factories, mines an...\n",
       "14  AP880401-0081  Ferrets are increasingly popular as pets, but ..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_corpus = pd.read_csv('./data/news_clipping.csv',encoding='utf-8')\n",
    "news_corpus.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "\n",
    "1. Tokenize each new clipping into sentences\n",
    "2. The list of sentences should be saved into a new column sentence_tokens within the same dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers\n",
    "\n",
    "# We can directly apply sent_tokenize to the text\n",
    "\n",
    "news_corpus['sentence_tokens'] = news_corpus.news_snippets.map(sent_tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_nr</th>\n",
       "      <th>news_snippets</th>\n",
       "      <th>sentence_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP880224-0195</td>\n",
       "      <td>The Bechtel Group Inc. offered in 1985 to sell...</td>\n",
       "      <td>[The Bechtel Group Inc. offered in 1985 to sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP881017-0144</td>\n",
       "      <td>A gunman took a 74-year-old woman hostage afte...</td>\n",
       "      <td>[A gunman took a 74-year-old woman hostage aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP881017-0219</td>\n",
       "      <td>Today is Saturday, Oct. 29, the 303rd day of 1...</td>\n",
       "      <td>[Today is Saturday, Oct. 29, the 303rd day of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP900117-0022</td>\n",
       "      <td>Cupid has a new message for lovers this Valent...</td>\n",
       "      <td>[Cupid has a new message for lovers this Valen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP880405-0167</td>\n",
       "      <td>The Reagan administration is weighing whether ...</td>\n",
       "      <td>[The Reagan administration is weighing whether...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_nr                                      news_snippets  \\\n",
       "0  AP880224-0195  The Bechtel Group Inc. offered in 1985 to sell...   \n",
       "1  AP881017-0144  A gunman took a 74-year-old woman hostage afte...   \n",
       "2  AP881017-0219  Today is Saturday, Oct. 29, the 303rd day of 1...   \n",
       "3  AP900117-0022  Cupid has a new message for lovers this Valent...   \n",
       "4  AP880405-0167  The Reagan administration is weighing whether ...   \n",
       "\n",
       "                                     sentence_tokens  \n",
       "0  [The Bechtel Group Inc. offered in 1985 to sel...  \n",
       "1  [A gunman took a 74-year-old woman hostage aft...  \n",
       "2  [Today is Saturday, Oct. 29, the 303rd day of ...  \n",
       "3  [Cupid has a new message for lovers this Valen...  \n",
       "4  [The Reagan administration is weighing whether...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is to check that there are new entries made in the column sentence_tokens\n",
    "news_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences  28\n",
      "['The Bechtel Group Inc. offered in 1985 to sell oil to Israel at a discount of at least $650 million for 10 years if it promised not to bomb a proposed Iraqi pipeline, a Foreign Ministry official said Wednesday.', \"But then-Prime Minister Shimon Peres said the offer from Bruce Rappaport, a partner in the San Francisco-based construction and engineering company, was ``unimportant,'' the senior official told The Associated Press.\", 'Peres, now foreign minister, never discussed the offer with other government ministers, said the official, who spoke on condition of anonymity.', \"The comments marked the first time Israel has acknowledged any offer was made for assurances not to bomb the planned $1 billion pipeline, which was to have run near Israel's border with Jordan.\", 'The pipeline was never built.', \"In San Francisco, Tom Flynn, vice president for public relations for the Bechtel Group, said the company did not make any offer to Peres but that Rappaport, a Swiss financier, made it without Bechtel's knowledge or consent.\", \"Another Bechtel spokesman, Al Donner, said Bechtel ``at no point'' in development of the pipeline project had anything to do with the handling of the oil.\", \"He said proposals submitted by the company ``did not include any specific arrangements for the handling of the oil or for the disposal of the oil once it reached the terminal.''\", \"Asked about Bechtel's disclaimers after they were made in San Francisco, the Israeli Foreign Ministry official said Peres believed Rappaport made the offer for the company.\", \"``Rappaport came to Peres as a representative of Bechtel and said he was speaking on behalf of Bechtel,'' the official said.\", \"``If he was not, he misrepresented himself.''\", 'The Jerusalem Post on Wednesday quoted sources close to Peres as saying that according to Rappaport, Bechtel had said the oil sales would have to be conducted through a third party to keep the sales secret from Iraq and Jordan.', 'The Foreign Ministry official said Peres did not take the offer seriously.', \"``This is a man who sees 10 people every day,'' he said.\", '``Thirty percent of them come with crazy ideas.', 'He just says, `Yes, yes.', \"We'll think about it.'\", \"That's how things work in Israel.''\", 'The offer appeared to be the one mentioned in a September 1985 memo to Attorney General Edwin Meese III.', \"The memo referred to an arrangement between Peres and Rappaport ``to the effect that Israel will receive somewhere between $65 million and $70 million a year for 10 years.''\", \"The memo from Meese friend E. Robert Wallach, Rappaport's attorney, also states, ``What was also indicated to me, and which would be denied everywhere, is that a portion of those funds will go directly to Labor,'' a reference to the political party Peres leads.\", 'The Wallach memo has become the focus of an investigation into whether Meese knew of a possibly improper payment.', \"Peres has denied any wrongdoing and has denounced the memo as ``complete nonsense.''\", 'The Israeli official said Rappaport, a native of Israel and a close friend of Peres, relayed the offer to Peres earlier in September.', '``Peres thought the offer was unimportant.', \"For him, the most important thing was to have an Iraqi oil port near Israel's border,'' the official said.\", \"``The thinking was that this would put Iraq in a position where it would not be able to wage war with Israel, out of concern for its pipeline.''\", \"A person answering the telephone at Rappaport's Swiss residence said he was out of town and could not be reached for comment.\"]\n"
     ]
    }
   ],
   "source": [
    "# this is to check the contents of one row of the column sentence_tokens\n",
    "\n",
    "my_sentences  = news_corpus['sentence_tokens'][0]\n",
    "\n",
    "print (\"number of sentences \", len(my_sentences))  # count the number of sentences\n",
    "print (my_sentences)       # prints out the sentence tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "1. For each sentences, further tokenize into uni-grams or words.\n",
    "2. The list of sentences should be saved into a new column sentence_word_tokens within the same dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a for loop goes through the list of sentences\n",
    "\n",
    "def  sentences_to_word_tokens(sentences):\n",
    "    # input: sentences is a list of string(sentence)\n",
    "    # return: a list that contains a list of tokens\n",
    "    word_tokens = []\n",
    "    for s in sentences:\n",
    "       word_tokens.append(word_tokenize(s))    \n",
    "    return word_tokens\n",
    "\n",
    "news_corpus['sentence_with_words_tokens'] = news_corpus.sentence_tokens.map(sentences_to_word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_nr</th>\n",
       "      <th>news_snippets</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>sentence_with_words_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP880224-0195</td>\n",
       "      <td>The Bechtel Group Inc. offered in 1985 to sell...</td>\n",
       "      <td>[The Bechtel Group Inc. offered in 1985 to sel...</td>\n",
       "      <td>[[The, Bechtel, Group, Inc., offered, in, 1985...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP881017-0144</td>\n",
       "      <td>A gunman took a 74-year-old woman hostage afte...</td>\n",
       "      <td>[A gunman took a 74-year-old woman hostage aft...</td>\n",
       "      <td>[[A, gunman, took, a, 74-year-old, woman, host...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP881017-0219</td>\n",
       "      <td>Today is Saturday, Oct. 29, the 303rd day of 1...</td>\n",
       "      <td>[Today is Saturday, Oct. 29, the 303rd day of ...</td>\n",
       "      <td>[[Today, is, Saturday, ,, Oct., 29, ,, the, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP900117-0022</td>\n",
       "      <td>Cupid has a new message for lovers this Valent...</td>\n",
       "      <td>[Cupid has a new message for lovers this Valen...</td>\n",
       "      <td>[[Cupid, has, a, new, message, for, lovers, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP880405-0167</td>\n",
       "      <td>The Reagan administration is weighing whether ...</td>\n",
       "      <td>[The Reagan administration is weighing whether...</td>\n",
       "      <td>[[The, Reagan, administration, is, weighing, w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_nr                                      news_snippets  \\\n",
       "0  AP880224-0195  The Bechtel Group Inc. offered in 1985 to sell...   \n",
       "1  AP881017-0144  A gunman took a 74-year-old woman hostage afte...   \n",
       "2  AP881017-0219  Today is Saturday, Oct. 29, the 303rd day of 1...   \n",
       "3  AP900117-0022  Cupid has a new message for lovers this Valent...   \n",
       "4  AP880405-0167  The Reagan administration is weighing whether ...   \n",
       "\n",
       "                                     sentence_tokens  \\\n",
       "0  [The Bechtel Group Inc. offered in 1985 to sel...   \n",
       "1  [A gunman took a 74-year-old woman hostage aft...   \n",
       "2  [Today is Saturday, Oct. 29, the 303rd day of ...   \n",
       "3  [Cupid has a new message for lovers this Valen...   \n",
       "4  [The Reagan administration is weighing whether...   \n",
       "\n",
       "                          sentence_with_words_tokens  \n",
       "0  [[The, Bechtel, Group, Inc., offered, in, 1985...  \n",
       "1  [[A, gunman, took, a, 74-year-old, woman, host...  \n",
       "2  [[Today, is, Saturday, ,, Oct., 29, ,, the, 30...  \n",
       "3  [[Cupid, has, a, new, message, for, lovers, th...  \n",
       "4  [[The, Reagan, administration, is, weighing, w...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full sentence is : \n",
      " The Bechtel Group Inc. offered in 1985 to sell oil to Israel at a discount of at least $650 million for 10 years if it promised not to bomb a proposed Iraqi pipeline, a Foreign Ministry official said Wednesday.\n",
      "\n",
      "The sentence is tokenize into : \n",
      " ['The', 'Bechtel', 'Group', 'Inc.', 'offered', 'in', '1985', 'to', 'sell', 'oil', 'to', 'Israel', 'at', 'a', 'discount', 'of', 'at', 'least', '$', '650', 'million', 'for', '10', 'years', 'if', 'it', 'promised', 'not', 'to', 'bomb', 'a', 'proposed', 'Iraqi', 'pipeline', ',', 'a', 'Foreign', 'Ministry', 'official', 'said', 'Wednesday', '.']\n"
     ]
    }
   ],
   "source": [
    "# Let's compare sentence_tokens and sentence_with_words_tokens for the first row, and the first sentence\n",
    "\n",
    "print (\"The full sentence is : \\n\" , news_corpus.sentence_tokens[0][0])\n",
    "print (\"\\nThe sentence is tokenize into : \\n\",  news_corpus.sentence_with_words_tokens[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "1. For each sentences, further tokenize into bigrams.\n",
    "2. The list of sentences should be saved into a new column sentence_with_bigram_tokens within the same dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a for loop goes through the list of sentences\n",
    "\n",
    "def  sentences_to_bigrams(sentences):\n",
    "    # input: sentences is a list of strings\n",
    "    # return: a list that contains a list of tokens\n",
    "    bigrams = []\n",
    "    for s in sentences:\n",
    "       word_tokens = word_tokenize(s)\n",
    "       bigram_list = list(ngrams(word_tokens,2))\n",
    "       bigrams.append(bigram_list)    \n",
    "    return bigrams\n",
    "\n",
    "# list(ngrams(word_tokenize(my_text),2))\n",
    "\n",
    "news_corpus['sentence_with_bigram'] = news_corpus.sentence_tokens.map(sentences_to_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full sentence is : \n",
      " The Bechtel Group Inc. offered in 1985 to sell oil to Israel at a discount of at least $650 million for 10 years if it promised not to bomb a proposed Iraqi pipeline, a Foreign Ministry official said Wednesday.\n",
      "\n",
      "The sentence is tokenize into words: \n",
      " ['The', 'Bechtel', 'Group', 'Inc.', 'offered', 'in', '1985', 'to', 'sell', 'oil', 'to', 'Israel', 'at', 'a', 'discount', 'of', 'at', 'least', '$', '650', 'million', 'for', '10', 'years', 'if', 'it', 'promised', 'not', 'to', 'bomb', 'a', 'proposed', 'Iraqi', 'pipeline', ',', 'a', 'Foreign', 'Ministry', 'official', 'said', 'Wednesday', '.']\n",
      "\n",
      "The sentence is tokenize into bigrams : \n",
      " [('The', 'Bechtel'), ('Bechtel', 'Group'), ('Group', 'Inc.'), ('Inc.', 'offered'), ('offered', 'in'), ('in', '1985'), ('1985', 'to'), ('to', 'sell'), ('sell', 'oil'), ('oil', 'to'), ('to', 'Israel'), ('Israel', 'at'), ('at', 'a'), ('a', 'discount'), ('discount', 'of'), ('of', 'at'), ('at', 'least'), ('least', '$'), ('$', '650'), ('650', 'million'), ('million', 'for'), ('for', '10'), ('10', 'years'), ('years', 'if'), ('if', 'it'), ('it', 'promised'), ('promised', 'not'), ('not', 'to'), ('to', 'bomb'), ('bomb', 'a'), ('a', 'proposed'), ('proposed', 'Iraqi'), ('Iraqi', 'pipeline'), ('pipeline', ','), (',', 'a'), ('a', 'Foreign'), ('Foreign', 'Ministry'), ('Ministry', 'official'), ('official', 'said'), ('said', 'Wednesday'), ('Wednesday', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Let's compare the sentences, sentence tokens, word tokens and bigram tokens for the first row, and the first sentence\n",
    "\n",
    "print (\"The full sentence is : \\n\" , news_corpus.sentence_tokens[0][0])\n",
    "print (\"\\nThe sentence is tokenize into words: \\n\",  news_corpus.sentence_with_words_tokens[0][0])\n",
    "print (\"\\nThe sentence is tokenize into bigrams : \\n\",  news_corpus.sentence_with_bigram[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full sentence is : \n",
      " He was the epitome of elegance and high standards.\n",
      "\n",
      "The sentence is tokenize into words: \n",
      " ['He', 'was', 'the', 'epitome', 'of', 'elegance', 'and', 'high', 'standards', '.']\n",
      "\n",
      "The sentence is tokenize into bigrams : \n",
      " [('He', 'was'), ('was', 'the'), ('the', 'epitome'), ('epitome', 'of'), ('of', 'elegance'), ('elegance', 'and'), ('and', 'high'), ('high', 'standards'), ('standards', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Let's compare the sentences, sentence tokens, word tokens and bigram tokens for the  11th row, and the third sentence\n",
    "\n",
    "print (\"The full sentence is : \\n\" , news_corpus.sentence_tokens[10][2])\n",
    "print (\"\\nThe sentence is tokenize into words: \\n\",  news_corpus.sentence_with_words_tokens[10][2])\n",
    "print (\"\\nThe sentence is tokenize into bigrams : \\n\",  news_corpus.sentence_with_bigram[10][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (optional)\n",
    "1. As you examine the results of the tokenization, you may come across strange combination of symbols, or characters that do not make senses or complicated the tokenization effort. In this case, you may wish to do use regular expression to substitute out these symbols, characters for something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
